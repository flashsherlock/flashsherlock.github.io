<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>MVPA on Fei</title><link>https://flashsherlock.github.io/tags/mvpa/</link><description>Recent content in MVPA on Fei</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 27 Sep 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://flashsherlock.github.io/tags/mvpa/index.xml" rel="self" type="application/rss+xml"/><item><title>Below-chance accuracy in MVPA</title><link>https://flashsherlock.github.io/2021/09/27/below-chance-accuracy-in-mvpa/</link><pubDate>Mon, 27 Sep 2021 00:00:00 +0000</pubDate><guid>https://flashsherlock.github.io/2021/09/27/below-chance-accuracy-in-mvpa/</guid><description>Sometimes, the decoding accuracy of MVPA may lower than chance level, which is confusing. I have found several reasons that may lead to below-chance accuracy in decoding analysis.
special data structure (bias) model parameters (linear vs. non linear) cross validation methods (leave-one-out vs. k-fold) sample size (small vs. large) In short, below-chance accuracy is likely caused by data structure and decoding methods, which can not be simply interpreted as anti-learning.</description></item></channel></rss>