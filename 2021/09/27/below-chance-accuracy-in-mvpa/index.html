<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=generator content="Hugo 0.110.0"><title>Below-chance accuracy in MVPA - Fei</title><meta property="og:title" content="Below-chance accuracy in MVPA - Fei"><link href=https://flashsherlock.github.io/favicon.ico rel=icon type=image/x-icon><link href=//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/atom-one-dark-reasonable.min.css rel=stylesheet type=text/css><link rel=stylesheet href=/css/fonts.css media=all><link rel=stylesheet href=/css/main.css media=all></head><body><div class=wrapper><header class=header><nav class=nav><a href=/ class=nav-logo><img src=/images/logo.png width=50 height=50 alt=Logo></a><ul class=nav-links><li><a href=/>Home</a></li><li><a href=http://zhouw.psych.ac.cn/>Lab</a></li><li><a href=https://github.com/flashsherlock/rwebsite>GitHub</a></li><li><a href=/about/>About</a></li></ul></nav></header><main class=content role=main><article class=article><h1 class=article-title>Below-chance accuracy in MVPA</h1><span class=article-duration>2 min read</span>
<span class=article-date>2021-09-27</span><div class=article-content><script src=/rmarkdown-libs/header-attrs/header-attrs.js></script><p>Sometimes, the decoding accuracy of MVPA may lower than chance level, which is confusing. I have found several reasons that may lead to below-chance accuracy in decoding analysis.</p><ul><li>special data structure (bias)</li><li>model parameters (linear vs. non linear)</li><li>cross validation methods (leave-one-out vs. k-fold)</li><li>sample size (small vs. large)</li></ul><p>In short, below-chance accuracy is likely caused by data structure and decoding methods, which <a href=http://mvpa.blogspot.com/2013/04/below-chance-classification-accuracy.html>can not be simply interpreted as anti-learning</a>.</p><p>For <a href=https://stats.stackexchange.com/questions/220582/svm-always-gives-me-in-average-below-chances-cross-validation-accuracy-with-ra>example</a>, when training with totally random data, the decoding accuracy should fluctuate at the chance level (50%), but actually it may lower than 50%.</p><pre class=r><code>library(&quot;ggplot2&quot;)
library(&quot;dplyr&quot;)
library(&quot;e1071&quot;)
# --------training function ---------
f_train &lt;- function(n, s = 1,
                    r = F, c = n) {
  # nv: number of features
  nv &lt;- 2
  # n: number of observations
  set.seed(s)
  # generate random data
  rNum &lt;- rnorm(nv * n)
  rNum &lt;- matrix(rNum, n, nv)
  d &lt;- as.data.frame(rNum)
  
  # generate random labels
  n2 &lt;- n / 2
  labels &lt;- c(array(1, n2),
              array(2, n2))
  if (r) {
  labels &lt;- sample.int(2,n,replace=T)}
  else {
  labels &lt;-  sample(labels)}
  d$condition &lt;- factor(labels)

  # training
  m_trained &lt;- svm(condition ~ .,
    data = d,
    cross = c,
    # cross = nrow(d), # leave one out
    kernel = &quot;linear&quot;,
    cost = 1
  )
  # get CV
  acc &lt;- m_trained$tot.accuracy
}</code></pre><pre class=r><code># no replacement, leave one out
p &lt;- expand.grid(iTest = 1:200, 
                 n = seq(10, 210, 50))
data_test &lt;- p %&gt;%
  group_by(iTest, n) %&gt;%
  do(data.frame(acc = f_train(.$n,.$iTest)))</code></pre><p><img src=/post/2021-09-27-below-chance-accuracy-in-mvpa_files/figure-html/plot_data-1.png width=384 style=display:block;margin:auto></p><p>As the sample size increases, variability decreases, and the mean accuracy tends to be 50%. However, there is a persistent small down bias on average, which can be eliminated using sampling with replacement.</p><pre class=r><code># with replacement, leave one out
data_test &lt;- p %&gt;%
  group_by(iTest, n) %&gt;%
  do(data.frame(acc = f_train(.$n,.$iTest,
                              r = T)))</code></pre><p><img src=/post/2021-09-27-below-chance-accuracy-in-mvpa_files/figure-html/unnamed-chunk-5-1.png width=384 style=display:block;margin:auto></p><p>In addition, change to 10-fold cross validation may also decrease the variability.</p><pre class=r><code># with replacement, 10-fold cross validation
data_test &lt;- p %&gt;%
  group_by(iTest, n) %&gt;%
  do(data.frame(acc = f_train(.$n,.$iTest,
                              r = F, c=10)))</code></pre><p><img src=/post/2021-09-27-below-chance-accuracy-in-mvpa_files/figure-html/unnamed-chunk-7-1.png width=384 style=display:block;margin:auto></p><p>Some references:</p><ol style=list-style-type:decimal><li><a href=https://doi.org/10.1016/j.neuroimage.2017.12.083>The same analysis approach: Practical protection against the pitfalls of novel neuroimaging analysis methods</a></li><li><a href=https://doi.org/10.1016/j.neuroimage.2018.09.074>How to control for confounds in decoding analyses of neuroimaging data</a></li><li><a href=https://doi.org/10.1002/hbm.23140>Classification Based Hypothesis Testing in Neuroscience: Below-Chance Level Classification Rates and Overlooked Statistical Properties of Linear Parametric Classifiers</a></li><li><a href=https://doi.org/10.1371/journal.pcbi.1006486>Multivariate classification of neuroimaging data with nested subclasses: Biased accuracy and implications for hypothesis testing</a></li><li><a href=http://dx.doi.org/10.1016/j.neuroimage.2017.08.005>Deconstructing multivariate decoding for the study of brain function</a></li></ol></div></article><section id=comments><div id=disqus_thread></div><script>var disqus_config=function(){};(function(){if(n=function(){var e=!0;try{e=window.self!==window.top}catch{}return e},n())return;var n,t=document,e=t.createElement("script");e.src="//gufei.disqus.com/embed.js",e.async=!0,e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)})()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript></section></main><footer class=footer><ul class=footer-links><li><a href=/index.xml type=application/rss+xml target=_blank>RSS feed</a></li><li><a href=mailto:guf@psych.ac.cn>Email: guf@psych.ac.cn</a></li><li><a href=https://gohugo.io/ class=footer-links-kudos>Made with <img src=/images/hugo-logo.png alt="Img link to Hugo website" width=22 height=22></a></li></ul></footer></div><script src=//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js></script>
<script src=//cdnjs.cloudflare.com/ajax/libs/highlightjs-line-numbers.js/2.8.0/highlightjs-line-numbers.min.js></script>
<script src=//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/languages/r.min.js></script>
<script src=//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/languages/yaml.min.js></script>
<script src=//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/languages/matlab.min.js></script>
<script>hljs.configure({languages:[]}),hljs.initHighlightingOnLoad(),hljs.initLineNumbersOnLoad()</script><script src=/js/math-code.js></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3WJ71TQ2TX"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-3WJ71TQ2TX",{anonymize_ip:!1})}</script></body></html>